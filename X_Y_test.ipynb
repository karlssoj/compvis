{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karlssoj/compvis/blob/Exempel3_Bildklassificering/X_Y_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4d6814a-fc4b-4f53-bc6f-098c29d7c050",
      "metadata": {
        "id": "c4d6814a-fc4b-4f53-bc6f-098c29d7c050"
      },
      "source": [
        "<h1> Klassificeringsexempel med faltningsnätverk (CNN) implementerat med Keras och Tensorflow </h1>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b Exempel3_Bildklassificering https://github.com/karlssoj/compvis.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k8L6aiYAV-F",
        "outputId": "40b1768a-f400-4c4f-b713-edebe6f7e109"
      },
      "id": "5k8L6aiYAV-F",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'compvis' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f220d2f-da3f-4c0a-b272-c01735136c48",
      "metadata": {
        "id": "1f220d2f-da3f-4c0a-b272-c01735136c48"
      },
      "source": [
        "I det här simplata exemplet tränar vi in en modell att kunna se skillnad mellan X och O. I katalogen X_O_training finns 2 kataloger O och X. Vardera katalog innehåller 4 träningsbilder på X respektive O. Sedan har vi en bild i samma katalog som denna notebookfil,\"test_image.jpg\" som vi använder för att testa om modellen gissar rätt. Observera att för att den här modellen ska fungera krävs det bilder där X och Y fyller hela bakrunden. För att modellen ska fungera med X och Y av olika storlekar placerade på olika ställen i bakgrunden krävs en bättre dataset.\n",
        "\n",
        "Skriptet är testkört i google colab (men kan nog även köras lokalt). Om du kör på colab."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "restricted-distinction",
      "metadata": {
        "id": "restricted-distinction"
      },
      "source": [
        "<b> 1. Importerar OpenCV och Matplotlibbelipippeli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "german-electronics",
      "metadata": {
        "id": "german-electronics"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "applied-commodity",
      "metadata": {
        "id": "applied-commodity"
      },
      "source": [
        "<b> 2. Importerar ImageDataGenerator från Keras-biblioteket för att kunna hantera träningsbilderna i X_O_training/o och X_O_training/x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "novel-recruitment",
      "metadata": {
        "id": "novel-recruitment"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "soviet-purpose",
      "metadata": {
        "id": "soviet-purpose"
      },
      "source": [
        "<b> 3. Skapar ett ImageDataGenerator-objekt med vissa inställningar för hur de inlästa träningsbilderna ska \"randomiseras\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qualified-nevada",
      "metadata": {
        "id": "qualified-nevada"
      },
      "outputs": [],
      "source": [
        "image_gen = ImageDataGenerator(rotation_range=30,    #slumpmässiga roteringar av bilderna i grader\n",
        "                             width_shift_range=0.1,  #slumpmässig skiftning i x-led (ett värde mellan 0 och 1)\n",
        "                             height_shift_range=0.1, #slumpmässig skiftning i y-led (ett värde mellan 0 och 1)\n",
        "                             rescale=1/255,          #skalar ner ett 8-bitars pixelvärde (0-255) till ett värde mellan 0 och 1\n",
        "                             zoom_range=0.6,         #slumpmässig zoom\n",
        "                             horizontal_flip=True)   #\"flippar\" bilden slumpmässigt i horisontalt läge"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "occasional-prisoner",
      "metadata": {
        "id": "occasional-prisoner"
      },
      "source": [
        "<b> 4. Läser in alla träningsbilder på X och O från respektive kataloger i X_O_training-katalogen. Alla bilder får storleken 100x100 pixlar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "straight-cheese",
      "metadata": {
        "id": "straight-cheese",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "0ed8bab6-1853-40b4-f0a1-98869f276327"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/XYExample/X_O_training'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-63fdc07a4be2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_image_gen = image_gen.flow_from_directory('/content/drive/MyDrive/XYExample/X_O_training',\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                 target_size=(100,100))\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/XYExample/X_O_training'"
          ]
        }
      ],
      "source": [
        "train_image_gen = image_gen.flow_from_directory('/content/drive/MyDrive/XYExample/X_O_training',\n",
        "                                                target_size=(100,100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "authentic-frost",
      "metadata": {
        "id": "authentic-frost"
      },
      "source": [
        "<b> 5. Träningsbilderna har automatiskt markerats enligt namnet på katalogerna de finns sparade i, dvs. O har labeln 0 och X har labeln 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "attempted-siemens",
      "metadata": {
        "id": "attempted-siemens"
      },
      "outputs": [],
      "source": [
        "print(train_image_gen.class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beginning-banking",
      "metadata": {
        "id": "beginning-banking"
      },
      "source": [
        "<b> 6. Importerar behövliga bibliotek från Keras för att kunna skapa en CNN-modell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "revised-anime",
      "metadata": {
        "id": "revised-anime"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "signed-concept",
      "metadata": {
        "id": "signed-concept"
      },
      "source": [
        "<b> 7. Skapar ett faltningslager (convolutional layer) bestående av 32 olika filters. Som aktiveringsfunktion används ReLU (för att bli av med alla negativa pixelvärden<br><br>\n",
        "\n",
        "<b> 8. Kör MaxPooling med 2x2 fönsterstorlek och hopp (stride) = 2<br><br>\n",
        "\n",
        "<b> 9. Formaterar om alla filtrerade bilder (i detta fall 32 stycken) till en enda array = flatten<br><br>\n",
        "\n",
        "<b> 10. Till slut mynnar allt ut i 2 neuroner i \"fully connected layer\", en för X och en för Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "funded-maker",
      "metadata": {
        "id": "funded-maker"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(100,100,3), activation = 'relu')) #Faltningslager med 32 filter\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))                                 #MaxPooling 2x2 fönsterstorlek och hopp (stride) = 2\n",
        "model.add(Flatten())                                                        #Formaterar om alla filtrerade blder (32 stycken) till en array\n",
        "model.add(Dense(units = 2, activation = \"sigmoid\"))                         #2 neuroner på slutet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "experimental-violation",
      "metadata": {
        "id": "experimental-violation"
      },
      "source": [
        "<b> 11. \"Kompilerar\" modellen. Optimizer är den metod man vill använda för att optimera alla vikter i nätet. Adam är en variant av gradient descent. Loss definierar \"loss function\", dvs. vad man vill använda för metod för att beräkna feluppskattningen under inträningen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "charged-marketplace",
      "metadata": {
        "id": "charged-marketplace"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "modified-insured",
      "metadata": {
        "id": "modified-insured",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a2f6a7-6c14-4f62-bb41-28f29de27cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 98, 98, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 49, 49, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 76832)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 153666    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 154562 (603.76 KB)\n",
            "Trainable params: 154562 (603.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "african-award",
      "metadata": {
        "id": "african-award"
      },
      "source": [
        "<b> 12. Startar själva inträningen på testdataset:en. Epochs definierar hur många ggr inlärningsalgoritmen kommer att gå igenom hela dataset:en."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collaborative-court",
      "metadata": {
        "tags": [],
        "id": "collaborative-court"
      },
      "outputs": [],
      "source": [
        "results = model.fit(train_image_gen, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "amateur-reynolds",
      "metadata": {
        "id": "amateur-reynolds"
      },
      "outputs": [],
      "source": [
        "plt.plot(results.history['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83648323-7fa3-4ef4-99f0-adb5d745fbbc",
      "metadata": {
        "id": "83648323-7fa3-4ef4-99f0-adb5d745fbbc"
      },
      "source": [
        "<b> 13. Vi laddar in en testbild (En bild som inte finns i träningsdataset:en) för att se hur bra vår modell fungerar! Observera att i detta simpla exempel så måste X eller O täcka mer eller mindre hela bilden och bakgrunden bör (antagligen) vara vit för att det ska fungera. För att få modellen att hitta X eller O även om de är skrivna i mindre storlek och i olika bakgrunder så måste träningsdataset:en utökas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "automotive-decision",
      "metadata": {
        "tags": [],
        "id": "automotive-decision"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras.utils as image\n",
        "test_image = '/content/drive/MyDrive/XYExample/test_image1.jpg'\n",
        "test_image = image.load_img(test_image, target_size=(100,100)) #laddar testbilden och sätter storleken till samma som träningsbilderna\n",
        "test_image = image.img_to_array(test_image)                    #konverterar till array-format\n",
        "\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "test_image = test_image/255                                    #Ändrar pixelvärden från 8-bitar (0-255) till värden mellan 0 och 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39c94ebb-3aae-4007-9105-36379e7f942f",
      "metadata": {
        "id": "39c94ebb-3aae-4007-9105-36379e7f942f"
      },
      "source": [
        "<b> 14. Vi startar \"predikteringen\" dvs. Som svar får vi konfidensvärden som berättar hur stor sannolikhten är att bilden innehåller ett X och hur stor sannolikheten är att bilden innehåller ett O"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bulgarian-option",
      "metadata": {
        "id": "bulgarian-option"
      },
      "outputs": [],
      "source": [
        "prob = model.predict(test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "separated-transsexual",
      "metadata": {
        "id": "separated-transsexual"
      },
      "outputs": [],
      "source": [
        "print(prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "worthy-milwaukee",
      "metadata": {
        "id": "worthy-milwaukee"
      },
      "outputs": [],
      "source": [
        "print(\"Sannolikheten att testbilden innehåller O: \" + str(prob[0][0]))\n",
        "print(\"Sannolikheten att testbilden innehåller X: \" + str(prob[0][1]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}